{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crayon RAG system - Basic RAG\n",
    "\n",
    " - Setup \n",
    " - Loading data\n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaIndex version: 0.11.18\n",
      "Weaviate version: 0.5.16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import llama_index\n",
    "import chromadb\n",
    "from importlib.metadata import version\n",
    "\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.settings import Settings\n",
    "\n",
    "\n",
    "print(f\"LlamaIndex version: {version('llama_index')}\")\n",
    "print(f\"Weaviate version: {version('chromadb')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this line of code if you have a local .env file\n",
    "load_dotenv(find_dotenv()) \n",
    "\n",
    "# Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "Settings.embed_model = OpenAIEmbedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='e745791d-a761-4baa-b302-41f921698320', embedding=None, metadata={'file_path': '/Users/tianyuliu/Code/llm/NLP_examples/src/llm/RAG/Crayon RAY/dataset/policy/Policy_1.txt', 'file_name': 'Policy_1.txt', 'file_type': 'text/plain', 'file_size': 6393, 'creation_date': '2024-11-16', 'last_modified_date': '2024-11-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='### Comprehensive Data Privacy Policy\\r\\n\\r\\n**1. Introduction**\\r\\n\\r\\n**Purpose of the Policy:**  \\r\\nAt [Company Name], safeguarding the privacy and security of personal data is a foundational principle of our business operations. This Data Privacy Policy is designed to transparently communicate our unwavering commitment to the protection of personal information across all aspects of our operations, reflecting our dedication to ethical practices and legal compliance.\\r\\n\\r\\n**Scope of the Policy:**  \\r\\nThis policy applies universally to all personal and sensitive information collected by [Company Name] from our customers, users, and employees. It encompasses all forms of data handling activities related to our services, products, and platforms, irrespective of the data collection medium or geographic location of the data subjects.\\r\\n\\r\\n**2. Data Collection Practices**\\r\\n\\r\\n**Types of Data Collected:**\\r\\n- **Personal Identification Information (PII):** Includes but is not limited to names, email addresses, physical addresses, telephone numbers, and payment details.\\r\\n- **Usage Data:** Comprises data on how individuals access and utilize our services, such as time stamps, clicked links, and viewed pages.\\r\\n- **Interaction Data:** Consists of data generated from user interactions with our services, including customer support interactions, user feedback, and activity logs.\\r\\n\\r\\n**Methods of Data Collection:**\\r\\n- **Direct Interactions:** Data collected via account registrations, service subscriptions, purchases, and direct communications.\\r\\n- **Automated Technologies:** Utilization of cookies, web beacons, and other similar technologies to gather data that helps us understand user preferences and site usage patterns.\\r\\n\\r\\n**Purpose of Data Collection:**  \\r\\nThe data collected serves multiple purposes:\\r\\n- To enhance the functionality and security of our services.\\r\\n- To personalize user experiences.\\r\\n- To support internal operations such as auditing, data analysis, and research to improve our offerings.\\r\\n- To train and refine our AI models, ensuring they are effective and ethical in their applications.\\r\\n\\r\\n**3. Data Storage and Management**\\r\\n\\r\\n**Data Storage Locations:**  \\r\\nData is securely stored in state-of-the-art data centers located in the United States, the European Union, and other jurisdictions, depending on the nature of the data and the services provided. Each location is chosen based on stringent security standards and data protection compliance.\\r\\n\\r\\n**Data Security Measures:**\\r\\n- **Encryption Techniques:** Utilizing advanced encryption standards to protect data at rest and in transit.\\r\\n- **Access Controls:** Implementation of role-based access controls (RBAC) to ensure that only authorized personnel have access to sensitive data, based on their job responsibilities.\\r\\n- **Regular Security Audits:** Conducting comprehensive security audits and vulnerability assessments to proactively manage and mitigate risks.\\r\\n\\r\\n**Data Retention Policy:**  \\r\\nWe adhere to a strict data retention policy that specifies the duration for which different types of data are held. Data is only retained as long as necessary to fulfill the stated purposes, after which it is securely deleted or anonymized.\\r\\n\\r\\n**4. Data Usage**\\r\\n\\r\\n**Internal Use of Data:**\\r\\n- **Product and Service Enhancement:** Using collected data to improve existing services and develop new offerings.\\r\\n- **AI Model Training:** Employing data in the training and refinement of AI algorithms to ensure accuracy and fairness.\\r\\n\\r\\n**Decision-Making Processes:**  \\r\\nWe utilize data-driven insights to facilitate automated and semi-automated decision-making processes. These are designed with a focus on fairness, accuracy, and accountability, incorporating mechanisms for human oversight and intervention when necessary.\\r\\n\\r\\n**User Benefits:**  \\r\\nThe use of data significantly enhances our ability to offer personalized and efficient services, improving overall user satisfaction and engagement.\\r\\n\\r\\n**5. Data Sharing and Disclosure**\\r\\n\\r\\n**Circumstances Under Which Data is Shared:**\\r\\n- **Service Providers:** Sharing with trusted partners who provide data processing services on our behalf, under strict confidentiality agreements.\\r\\n- **Legal and Compliance Requirements:** Disclosing data when required by law, such as in response to legal processes or for compliance with regulatory obligations.\\r\\n\\r\\n**Safeguards for Data Sharing:**  \\r\\nWe implement robust contractual protections to ensure that any data shared is treated in accordance with our privacy standards and applicable laws.\\r\\n\\r\\n**User Control and Consent:**  \\r\\nProviding users with comprehensive control over their personal information, including mechanisms to grant or withdraw consent, access data, and request data deletion.\\r\\n\\r\\n**6. Rights of Data Subjects**\\r\\n\\r\\n**Access to Data:**  \\r\\nUsers have the right to access their data and receive information about its processing, ensuring they can verify legality and accuracy.\\r\\n\\r\\n**Data Correction and Deletion:**  \\r\\nWe provide options for users to correct inaccuracies in their data or to have it erased from our systems, subject to certain conditions.\\r\\n\\r\\n**Data Portability:**  \\r\\nFacilitating the right of data portability, allowing users to obtain and reuse their personal data across different services.\\r\\n\\r\\n**7. Policy Enforcement and Compliance**\\r\\n\\r\\n**Compliance with Laws and Regulations:**  \\r\\nOur policy adheres to international, federal, and state regulations, ensuring compliance with laws such as GDPR, CCPA, and others.\\r\\n\\r\\n**Reporting and Addressing Violations:**  \\r\\nWe have established a formal procedure for addressing data privacy concerns and policy violations, ensuring prompt and effective resolution.\\r\\n\\r\\n**Updates to the Policy:**\\r\\n\\r\\n  \\r\\nThis policy may be updated periodically to reflect changes in our practices or legal requirements, with substantial changes communicated directly to users.\\r\\n\\r\\n**8. Contact Information**\\r\\n\\r\\n**Contact Details for Privacy Concerns:**  \\r\\nFor further inquiries or concerns regarding our Data Privacy Policy, users can contact our Data Protection Officer at [privacy@email.com].\\r\\n\\r\\n**9. Conclusion**\\r\\n\\r\\nAt [Company Name], we are dedicated to maintaining the trust of our users by adhering to the highest standards of data privacy and security. We encourage all users to review this policy regularly to stay informed of how we protect their personal information.\\r\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='7b313071-ed6a-4062-bb14-26582f01474b', embedding=None, metadata={'file_path': '/Users/tianyuliu/Code/llm/NLP_examples/src/llm/RAG/Crayon RAY/dataset/policy/Policy_2.txt', 'file_name': 'Policy_2.txt', 'file_type': 'text/plain', 'file_size': 5319, 'creation_date': '2024-11-16', 'last_modified_date': '2024-11-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"### Comprehensive AI Ethics Policy Document\\r\\n\\r\\n#### 1. Introduction\\r\\nThis document articulates [Company Name]'s unwavering commitment to the ethical development, deployment, and management of artificial intelligence (AI). As a leader in AI innovation, we recognize our responsibility to ensure that our technologies enhance societal well-being and are utilized in a manner that respects human dignity and rights. This policy provides the ethical guidelines our employees and partners must follow to uphold integrity and promote the beneficial use of AI.\\r\\n\\r\\n#### 2. Scope\\r\\nThis policy encompasses all AI-related activities at [Company Name], including the design, development, procurement, deployment, maintenance, and decommissioning of AI systems. It applies universally across our global operations, affecting all employees, contractors, consultants, and business partners involved with AI technologies.\\r\\n\\r\\n#### 3. Definitions\\r\\n- **Artificial Intelligence (AI):** Systems or machines that simulate human intelligence processes, capable of learning from data and experience, making autonomous decisions, and performing tasks traditionally requiring human intelligence.\\r\\n- **Fairness:** The attribute of an AI system that impartially, justly, and equitably handles decisions without embedding or perpetuating biases.\\r\\n- **Transparency:** The quality of being open in communication and documentation regarding the methodologies, data, and algorithms used in AI systems.\\r\\n- **Non-Discrimination:** The assurance that AI systems do not engage in or propagate biases based on race, gender, ethnicity, religion, or other prohibited factors.\\r\\n- **Accountability:** The principle that individuals and organizations are responsible for the outcomes of AI systems, including the obligation to rectify any harm caused.\\r\\n\\r\\n#### 4. Principles\\r\\n##### 4.1 Fairness\\r\\n- Develop and implement an ongoing bias monitoring framework that includes periodic reviews of AI systems to identify and mitigate biases.\\r\\n- Collaborate with interdisciplinary teams, including ethicists and sociologists, to understand and address the nuances of fairness in diverse cultural and social contexts.\\r\\n\\r\\n##### 4.2 Transparency\\r\\n- Enhance transparency by developing interfaces that allow users to query AI decisions and receive explanations in understandable terms.\\r\\n- Document all AI systems' decision-making processes and methodologies, ensuring that this documentation is accessible to all relevant stakeholders and regularly updated.\\r\\n\\r\\n##### 4.3 Non-Discrimination\\r\\n- Establish a rigorous protocol for the continuous auditing of AI algorithms and training data sets to detect and correct biases that could lead to discriminatory outcomes.\\r\\n- Create an independent review committee to evaluate and approve all new AI projects for compliance with non-discrimination standards before they are deployed.\\r\\n\\r\\n##### 4.4 Accountability\\r\\n- Implement a standardized AI incident reporting system, which ensures all potential issues are logged, investigated, and addressed promptly.\\r\\n- Define clear escalation paths for ethical concerns related to AI, including a direct line to the AI Ethics Board.\\r\\n\\r\\n#### 5. Implementation\\r\\n##### 5.1 Governance\\r\\n- Enhance the role of the AI Ethics Board to include periodic ethical reviews of existing AI systems, not just new projects, with the authority to recommend modifications or discontinuations based on ethical evaluations.\\r\\n- Introduce a third-party ethics audit performed annually to provide an unbiased assessment of our AI practices.\\r\\n\\r\\n##### 5.2 Risk Assessment\\r\\n- Develop a comprehensive ethical risk assessment toolkit that includes templates, best practices, and guidelines to standardize the assessment process across the company.\\r\\n- Employ predictive modeling to forecast potential ethical issues under various operational scenarios and use these insights to guide AI system development.\\r\\n\\r\\n##### 5.3 Training and Awareness\\r\\n- Establish a continuous learning program on AI ethics, mandating regular updates to training content as ethical standards and technologies evolve.\\r\\n- Promote an ethical AI culture by integrating ethics discussions into regular team meetings and decision-making processes.\\r\\n\\r\\n##### 5.4 Reporting and Auditing\\r\\n- Set up an anonymous ethics violation reporting system, encouraging stakeholders to report any unethical AI practices without fear of retribution.\\r\\n- Publicly release a detailed annual report on ethical practices, challenges, and advancements in AI to maintain transparency and encourage industry-wide ethical standards.\\r\\n\\r\\n#### 6. Enforcement\\r\\n- Specify the procedures for handling violations of this ethics policy, including detailed descriptions of disciplinary actions ranging from warnings to termination, depending on the severity of the breach.\\r\\n\\r\\n#### 7. Review and Updates\\r\\n- Commit to a biannual review cycle for this policy to stay aligned with technological advancements, legal changes, and evolving societal norms regarding AI ethics.\\r\\n\\r\\n### Conclusion\\r\\nBy adhering to the expanded guidelines outlined in this AI Ethics Policy, [Company Name] commits to being at the forefront of ethical AI development. This policy ensures that our technologies are used in a way that is beneficial and just, fostering trust and collaboration with all stakeholders involved.\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " Document(id_='1c3eb03b-3bc8-438c-81b9-86d529f532b8', embedding=None, metadata={'file_path': '/Users/tianyuliu/Code/llm/NLP_examples/src/llm/RAG/Crayon RAY/dataset/policy/Policy_3.txt', 'file_name': 'Policy_3.txt', 'file_type': 'text/plain', 'file_size': 7306, 'creation_date': '2024-11-16', 'last_modified_date': '2024-11-16'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='## Model Governance Policy\\r\\n\\r\\n### 1. Introduction\\r\\n#### 1.1 Purpose\\r\\nThis document delineates the guiding principles and procedures for the governance of artificial intelligence (AI) model development, deployment, and monitoring within our organization. It aims to establish a robust framework that ensures our AI models operate effectively, ethically, and in compliance with all applicable regulations. The policy serves to safeguard our technological innovations, uphold our ethical commitments, and maintain stakeholder trust.\\r\\n\\r\\n#### 1.2 Scope\\r\\nThe Model Governance Policy applies to all AI models developed, deployed, or managed by our company, across all departments and subsidiaries. It includes models at various stages of the lifecycle, from initial conception and development through to deployment and continuous monitoring.\\r\\n\\r\\n#### 1.3 Audience\\r\\nThis policy is intended for a broad range of stakeholders including AI developers, project managers, compliance officers, and executive leadership. Each role has a responsibility to understand and implement the guidelines set forth in this policy to ensure effective and ethical model governance.\\r\\n\\r\\n### 2. Policy Statement\\r\\n#### 2.1 Commitment to Ethical AI\\r\\nOur company is committed to the highest standards of ethical conduct in all our AI endeavors. We pledge to develop and deploy AI technologies that are fair, transparent, accountable, and secure, respecting privacy and ensuring non-discrimination.\\r\\n\\r\\n### 3. Definitions and Key Terms\\r\\n#### 3.1 Glossary\\r\\n**AI Model**: A software algorithm designed to perform tasks that typically require human intelligence, such as decision-making, prediction, or pattern recognition.\\r\\n**Deployment**: The process of integrating an AI model into operational environments where it can start performing its intended tasks.\\r\\n**Monitoring**: Continuous oversight of AI models to ensure they operate as expected and do not deviate from predefined norms and ethics.\\r\\n\\r\\n### 4. Governance Structure\\r\\n#### 4.1 Governance Roles and Responsibilities\\r\\n- **AI Governance Board**: Oversees all AI initiatives and ensures adherence to this policy.\\r\\n- **Model Owners**: Responsible for the performance and compliance of specific AI models.\\r\\n- **Data Scientists**: Tasked with the development and fine-tuning of AI models according to ethical guidelines.\\r\\n\\r\\n#### 4.2 Decision-Making Authorities\\r\\nDecision-making within the realm of AI model governance is distributed according to the criticality and impact of the decisions. Routine decisions are managed at the departmental level, while strategic and high-impact decisions are escalated to the AI Governance Board.\\r\\n\\r\\n### 5. Development and Testing\\r\\n#### 5.1 Model Design and Development Process\\r\\nAI model development must follow a structured process that includes requirement gathering, design, development, and initial testing phases. Each phase should be documented thoroughly to ensure transparency and accountability. The design phase should consider ethical implications, potential biases, and intended and unintended uses of the model.\\r\\n\\r\\n#### 5.2 Testing and Validation\\r\\nModels must undergo rigorous testing to validate their accuracy, performance, and fairness. Validation tests should be designed to cover various operational scenarios and should include stress and failure mode analysis. Documentation of all test results is mandatory for auditability and further review.\\r\\n\\r\\n### 6. Deployment\\r\\n#### 6.1 Deployment Procedures\\r\\nBefore deployment, AI models must be reviewed by the AI Governance Board to ensure compliance with all internal and external standards. This review includes a final round of testing focused on security and performance under expected operational conditions.\\r\\n\\r\\n#### 6.2 Deployment Monitoring\\r\\nPost-deployment, AI models require continuous monitoring to detect and correct any deviation from their expected operational performance or ethical standards. Monitoring strategies include the implementation of automated performance tracking tools and periodic model audits.\\r\\n\\r\\n### 7. Monitoring and Maintenance\\r\\n#### 7.1 Performance Monitoring\\r\\nContinuous performance evaluation is essential to ensure that AI models function as intended over time. This involves regular checks against performance metrics and real-world outcomes to identify any degradation or deviation from expected results.\\r\\n\\r\\n#### 7.2 Model Updating and Maintenance\\r\\nModels must be maintained and updated regularly to adapt to new data, changing environments, or updated regulatory requirements. The maintenance schedule and procedures should be clearly defined and followed meticulously to ensure ongoing relevance and compliance of the AI models.\\r\\n\\r\\n### 8. Compliance and Reporting\\r\\n#### 8.1 Regulatory Compliance\\r\\nAll model governance activities must adhere to relevant local, national, and international AI regulations. This compliance is critical not only for legal reasons but also to maintain public trust and uphold ethical standards.\\r\\n\\r\\n#### 8.2 Reporting Mechanisms\\r\\nThe company maintains a detailed reporting system for all AI governance activities. These reports are made available to regulatory bodies as required and are an essential tool for internal audits and transparency.\\r\\n\\r\\n### 9. Risk Management\\r\\n#### 9.1 Risk Identification and Assessment\\r\\nIdentifying potential risks associated with AI models, including ethical risks, technical failures, and data privacy concerns, is crucial. Each identified risk must be assessed for its impact and likelihood.\\r\\n\\r\\n#### 9.2 Risk Response and Mitigation\\r\\nFor each identified risk, a specific mitigation strategy must be developed and implemented. These strategies may include additional training, enhanced security measures, or changes to model development practices.\\r\\n\\r\\n### 10.\\r\\n\\r\\n Training and Awareness\\r\\n#### 10.1 Employee Training Programs\\r\\nWe provide comprehensive training to all employees involved in AI development and management. This training covers technical aspects of AI, ethical considerations, and policy guidelines.\\r\\n\\r\\n#### 10.2 Awareness Campaigns\\r\\nRegular awareness campaigns are conducted to keep all staff informed about the latest developments in AI governance, emerging ethical considerations, and new regulatory requirements.\\r\\n\\r\\n### 11. Policy Review and Update\\r\\n#### 11.1 Review Schedule\\r\\nThis policy is reviewed bi-annually to ensure its relevance and effectiveness. Reviews are conducted by the AI Governance Board in consultation with key stakeholders.\\r\\n\\r\\n#### 11.2 Updating Procedures\\r\\nAny updates to the policy must be thoroughly documented, approved by the AI Governance Board, and communicated to all affected parties before implementation.\\r\\n\\r\\n### 12. Appendices and Supporting Documents\\r\\n#### 12.1 Related Documents\\r\\nRelated policies, guidelines, and documents are listed in the Appendix. These documents provide additional information and operational details supporting this policy.\\r\\n\\r\\n#### 12.2 Contact Information\\r\\nFor questions or clarifications regarding any aspect of this policy, please refer to the contact list provided in the Appendix.\\r\\n\\r\\nThis document aims to ensure that all AI-related activities are conducted responsibly, ethically, and in compliance with all necessary guidelines and regulations, maintaining the integrity and trustworthiness of our AI applications.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# Load data\n",
    "documents = SimpleDirectoryReader(\"./dataset/policy\").load_data()\n",
    "\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Chunk documents into Nodes\n",
    "\n",
    "As the whole document is too large to fit into the context window of the LLM, you will need to partition it into smaller text chunks, which are called Nodes in LlamaIndex.\n",
    "\n",
    "With the SentenceWindowNodeParser each sentence is stored as a chunk together with a larger window of text surrounding the original sentence as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      "##### 4.4 Accountability\n",
      "- Implement a standardized AI incident reporting system, which ensures all potential issues are logged, investigated, and addressed promptly.\n",
      "- Define clear escalation paths for ethical concerns related to AI, including a direct line to the AI Ethics Board.\n",
      "\n",
      "#### 5. Implementation\n",
      "##### 5.1 Governance\n",
      "- Enhance the role of the AI Ethics Board to include periodic ethical reviews of existing AI systems, not just new projects, with the authority to recommend modifications or discontinuations based on ethical evaluations.\n",
      "- Introduce a third-party ethics audit performed annually to provide an unbiased assessment of our AI practices.\n",
      "\n",
      "##### 5.2 Risk Assessment\n",
      "- Develop a comprehensive ethical risk assessment toolkit that includes templates, best practices, and guidelines to standardize the assessment process across the company.\n",
      "- Employ predictive modeling to forecast potential ethical issues under various operational scenarios and use these insights to guide AI system development.\n",
      "\n",
      "##### 5.3 Training and Awareness\n",
      "- Establish a continuous learning program on AI ethics, mandating regular updates to training content as ethical standards and technologies evolve.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=258, chunk_overlap=50)\n",
    "\n",
    "# Extract nodes from documents\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# This block of code is to showcase what the nodes looks like\n",
    "i=10\n",
    "print(f\"Text: \\n{nodes[i].text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Store the data into Vector DB (chromadb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "\n",
    "# initialize client, setting path to save data\n",
    "db = chromadb.PersistentClient(path=\"./dataset/chroma_db\")\n",
    "\n",
    "# create collection\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "# assign chroma as the vector_store to the context\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# create your index\n",
    "# build VectorStoreIndex that takes care of chunking documents\n",
    "# and encoding chunks to embeddings for future retrieval\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "\n",
    "# Create an index from the documents and save it to the disk.\n",
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents, storage_context=storage_context\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create a retriever using Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll now create a retriever that can retrieve data embeddings from the newly created Chroma vector store.\n",
    "\n",
    "First, initialize the PersistentClient with the same path you specified while creating the Chroma vector store. You'll then retrieve the collection \"quickstart\" you created previously from Chroma. You can use this collection to initialize the ChromaVectorStore in which you store the embeddings of the website data. You can then use the from_vector_store function of VectorStoreIndex to load the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Develop a comprehensive ethical risk assessment toolkit that includes templates, best practices, and guidelines to standardize the assessment process across the company. Employ predictive modeling to forecast potential ethical issues under various operational scenarios and use these insights to guide AI system development.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load from disk\n",
    "load_client = chromadb.PersistentClient(path=\"./dataset/chroma_db\")\n",
    "\n",
    "# Fetch the collection\n",
    "chroma_collection = load_client.get_collection(\"quickstart\")\n",
    "\n",
    "# Fetch the vector store\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "# Get the index from the vector store\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)\n",
    "\n",
    "# Check if the retriever is working by trying to fetch the relevant docs related\n",
    "# to the phrase 'MMLU' (Multimodal Machine Learning Understanding).\n",
    "# If the length is greater than zero, it means that the retriever is\n",
    "# functioning well.\n",
    "# You can ask questions about your data using a generic interface called\n",
    "# a query engine. You have to use the `as_query_engine` function of the\n",
    "# index to create a query engine and use the `query` function of query engine\n",
    "# to inquire the index.\n",
    "test_query_engine = index.as_query_engine()\n",
    "response = test_query_engine.query(\"AI Risk Assessment\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: ##### 4.4 Accountability\n",
      "- Implement a standardized AI incident reporting system, which ensures all potential issues are logged, investigated, and addressed promptly.\n",
      "- Define clear escalation paths for ethical concerns related to AI, including a direct line to the AI Ethics Board.\n",
      "\n",
      "#### 5. Implementation\n",
      "##### 5.1 Governance\n",
      "- Enhance the role of the AI Ethics Board to include periodic ethical reviews of existing AI systems, not just new projects, with the authority to recommend modifications or discontinuations based on ethical evaluations.\n",
      "- Introduce a third-party ethics audit performed annually to provide an unbiased assessment of our AI practices.\n",
      "\n",
      "##### 5.2 Risk Assessment\n",
      "- Develop a comprehensive ethical risk assessment toolkit that includes templates, best practices, and guidelines to standardize the assessment process across the company.\n",
      "- Employ predictive modeling to forecast potential ethical issues under various operational scenarios and use these insights to guide AI system development.\n",
      "\n",
      "##### 5.3 Training and Awareness\n",
      "- Establish a continuous learning program on AI ethics, mandating regular updates to training content as ethical standards and technologies evolve.\n"
     ]
    }
   ],
   "source": [
    "sentence = response.source_nodes[0].node.text\n",
    "\n",
    "\n",
    "print(f\"Original Sentence: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### 4.4 Accountability\n",
      "- Implement a standardized AI incident reporting system, which ensures all potential issues are logged, investigated, and addressed promptly.\n",
      "- Define clear escalation paths for ethical concerns related to AI, including a direct line to the AI Ethics Board.\n",
      "\n",
      "#### 5. Implementation\n",
      "##### 5.1 Governance\n",
      "- Enhance the role of the AI Ethics Board to include periodic ethical reviews of existing AI systems, not just new projects, with the authority to recommend modifications or discontinuations based on ethical evaluations.\n",
      "- Introduce a third-party ethics audit performed annually to provide an unbiased assessment of our AI practices.\n",
      "\n",
      "##### 5.2 Risk Assessment\n",
      "- Develop a comprehensive ethical risk assessment toolkit that includes templates, best practices, and guidelines to standardize the assessment process across the company.\n",
      "- Employ predictive modeling to forecast potential ethical issues under various operational scenarios and use these insights to guide AI system development.\n",
      "\n",
      "##### 5.3 Training and Awareness\n",
      "- Establish a continuous learning program on AI ethics, mandating regular updates to training content as ethical standards and technologies evolve.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=2,\n",
    ")\n",
    "\n",
    "#Finding out the nodes for the new query:\n",
    "nodes=retriever.retrieve(\"AI Risk Assessment\")\n",
    "print(nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Policy_2.txt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(f\"{nodes[0]}\")\n",
    "nodes[0].metadata[\"file_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who are you!\"}\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.2\n",
    ")\n",
    "print(chat_completion)\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-examples-2S-piTS9-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
