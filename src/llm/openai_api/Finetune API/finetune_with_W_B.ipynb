{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning OpenAI models with Weights & Biases\n",
    "\n",
    "https://colab.research.google.com/github/wandb/examples/blob/master/colabs/openai/Fine_tune_OpenAI_with_Weights_and_Biases.ipynb#scrollTo=nMaTVSdD6Fpc\n",
    "\n",
    "- Data preparation: training data; validation data; Upload files\n",
    "- Fine-tuned model: fine-tuned model with job_id\n",
    "- Evaluation\n",
    "- Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import wandb\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "\n",
    "from openai import OpenAI\n",
    "import wandb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_PROJECT = \"OpenAI-Fine-Tune-test\"\n",
    "\n",
    "# # Enter credentials\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 43.97 examples/s]\n",
      "Generating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 109/109 [00:00<00:00, 930.20 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# download a dataset from LegalBench, a project to curate tasks for evaluating legal reasoning, \n",
    "# specifically the Contract NLI Explicit Identification task.\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Download the data, merge into a single dataset and shuffle\n",
    "dataset = load_dataset(\"nguha/legalbench\", \"contract_nli_explicit_identification\")\n",
    "\n",
    "data = []\n",
    "for d in dataset[\"train\"]:\n",
    "  data.append(d)\n",
    "\n",
    "for d in dataset[\"test\"]:\n",
    "  data.append(d)\n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "for idx, d in enumerate(data):\n",
    "  d[\"new_index\"] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117,\n",
       " [{'answer': 'No',\n",
       "   'index': '77',\n",
       "   'text': 'The obligations of the Receiving Party pursuant to the provisions of this Agreement shall not apply to any Confidential Information that ‚Äì 8.3 is developed independently of the Disclosing Party by the Receiving Party in circumstances that do not amount to a breach of the provisions of this Agreement; ',\n",
       "   'document_name': 'AfriGIS_Client-NDA_Template_2019.pdf',\n",
       "   'new_index': 0},\n",
       "  {'answer': 'No',\n",
       "   'index': '97',\n",
       "   'text': 'Except as expressly authorized by prior written consent of the Disclosing Party, the Receiving Party shall: (e) use all Confidential Information received by it for the purposes described in subsection  (a) of this Section 2 and for no other purpose whatsoever. ',\n",
       "   'document_name': '1173495_0001047469-03-033872_a2118144zex-10_12.txt',\n",
       "   'new_index': 1}])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format our Data for Chat Completion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt_zero_shot = \"Identify if the clause provides that all Confidential Information shall be expressly identified by the Disclosing Party. Answer with only `Yes` or `No`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 30\n",
    "n_test = len(data) - n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,\n",
       " 87,\n",
       " 87,\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': 'Identify if the clause provides that all Confidential Information shall be expressly identified by the Disclosing Party. Answer with only `Yes` or `No`'},\n",
       "   {'role': 'user',\n",
       "    'content': 'The definition of Information shall not include information that: (e) is developed by the Receiving Party independently of Information disclosed by the Disclosing Party and without breach of this Agreement. '},\n",
       "   {'role': 'assistant', 'content': 'No'}]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_messages = []\n",
    "test_messages = []\n",
    "\n",
    "for d in data:\n",
    "  prompts = []\n",
    "  prompts.append({\"role\": \"system\", \"content\": base_prompt_zero_shot})\n",
    "  prompts.append({\"role\": \"user\", \"content\": d[\"text\"]})\n",
    "  prompts.append({\"role\": \"assistant\", \"content\": d[\"answer\"]})\n",
    "\n",
    "  if int(d[\"new_index\"]) < n_train:\n",
    "    train_messages.append({'messages': prompts})\n",
    "  else:\n",
    "    test_messages.append({'messages': prompts})\n",
    "\n",
    "len(train_messages), len(test_messages), n_test, train_messages[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data to jsonl first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data in a train and test file first\n",
    "train_file_path = 'encoded_train_data.jsonl'\n",
    "with open(train_file_path, 'w') as file:\n",
    "    for item in train_messages:\n",
    "        line = json.dumps(item)\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "test_file_path = 'encoded_test_data.jsonl'\n",
    "with open(test_file_path, 'w') as file:\n",
    "    for item in test_messages:\n",
    "        line = json.dumps(item)\n",
    "        file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate that our training data is in the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we specify the data path and open the JSONL file\n",
    "\n",
    "def openai_validate_data(dataset_path):\n",
    "  data_path = dataset_path\n",
    "\n",
    "  # Load dataset\n",
    "  with open(data_path) as f:\n",
    "      dataset = [json.loads(line) for line in f]\n",
    "\n",
    "  # We can inspect the data quickly by checking the number of examples and the first item\n",
    "\n",
    "  # Initial dataset stats\n",
    "  print(\"Num examples:\", len(dataset))\n",
    "  print(\"First example:\")\n",
    "  for message in dataset[0][\"messages\"]:\n",
    "      print(message)\n",
    "\n",
    "  # Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the Chat completions message structure\n",
    "\n",
    "  # Format error checks\n",
    "  format_errors = defaultdict(int)\n",
    "\n",
    "  for ex in dataset:\n",
    "      if not isinstance(ex, dict):\n",
    "          format_errors[\"data_type\"] += 1\n",
    "          continue\n",
    "\n",
    "      messages = ex.get(\"messages\", None)\n",
    "      if not messages:\n",
    "          format_errors[\"missing_messages_list\"] += 1\n",
    "          continue\n",
    "\n",
    "      for message in messages:\n",
    "          if \"role\" not in message or \"content\" not in message:\n",
    "              format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "          if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
    "              format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "          if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
    "              format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "          content = message.get(\"content\", None)\n",
    "          if not content or not isinstance(content, str):\n",
    "              format_errors[\"missing_content\"] += 1\n",
    "\n",
    "      if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "          format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "  if format_errors:\n",
    "      print(\"Found errors:\")\n",
    "      for k, v in format_errors.items():\n",
    "          print(f\"{k}: {v}\")\n",
    "  else:\n",
    "      print(\"No errors found\")\n",
    "\n",
    "  # Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n",
    "\n",
    "  # Token counting functions\n",
    "  encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "  # not exact!\n",
    "  # simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "  def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          num_tokens += tokens_per_message\n",
    "          for key, value in message.items():\n",
    "              num_tokens += len(encoding.encode(value))\n",
    "              if key == \"name\":\n",
    "                  num_tokens += tokens_per_name\n",
    "      num_tokens += 3\n",
    "      return num_tokens\n",
    "\n",
    "  def num_assistant_tokens_from_messages(messages):\n",
    "      num_tokens = 0\n",
    "      for message in messages:\n",
    "          if message[\"role\"] == \"assistant\":\n",
    "              num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "      return num_tokens\n",
    "\n",
    "  def print_distribution(values, name):\n",
    "      print(f\"\\n#### Distribution of {name}:\")\n",
    "      print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "      print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "      print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "  # Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n",
    "\n",
    "  # Warnings and tokens counts\n",
    "  n_missing_system = 0\n",
    "  n_missing_user = 0\n",
    "  n_messages = []\n",
    "  convo_lens = []\n",
    "  assistant_message_lens = []\n",
    "\n",
    "  for ex in dataset:\n",
    "      messages = ex[\"messages\"]\n",
    "      if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "          n_missing_system += 1\n",
    "      if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "          n_missing_user += 1\n",
    "      n_messages.append(len(messages))\n",
    "      convo_lens.append(num_tokens_from_messages(messages))\n",
    "      assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "  print(\"Num examples missing system message:\", n_missing_system)\n",
    "  print(\"Num examples missing user message:\", n_missing_user)\n",
    "  print_distribution(n_messages, \"num_messages_per_example\")\n",
    "  print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "  print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "  n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "  print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
    "\n",
    "  # Pricing and default n_epochs estimate\n",
    "  MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "  MIN_TARGET_EXAMPLES = 100\n",
    "  MAX_TARGET_EXAMPLES = 25000\n",
    "  TARGET_EPOCHS = 3\n",
    "  MIN_EPOCHS = 1\n",
    "  MAX_EPOCHS = 25\n",
    "\n",
    "  n_epochs = TARGET_EPOCHS\n",
    "  n_train_examples = len(dataset)\n",
    "  if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "      n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "  elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "      n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "  n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "  print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "  print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "  print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "  print(\"See pricing page to estimate total costs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 30\n",
      "First example:\n",
      "{'role': 'system', 'content': 'Identify if the clause provides that all Confidential Information shall be expressly identified by the Disclosing Party. Answer with only `Yes` or `No`'}\n",
      "{'role': 'user', 'content': 'The obligations of the Receiving Party pursuant to the provisions of this Agreement shall not apply to any Confidential Information that ‚Äì 8.3 is developed independently of the Disclosing Party by the Receiving Party in circumstances that do not amount to a breach of the provisions of this Agreement; '}\n",
      "{'role': 'assistant', 'content': 'No'}\n",
      "No errors found\n",
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 61, 273\n",
      "mean / median: 128.83333333333334, 123.5\n",
      "p5 / p95: 78.8, 186.90000000000003\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 1, 1\n",
      "mean / median: 1.0, 1.0\n",
      "p5 / p95: 1.0, 1.0\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
      "Dataset has ~3865 tokens that will be charged for during training\n",
      "By default, you'll train for 3 epochs on this dataset\n",
      "By default, you'll be charged for ~11595 tokens\n",
      "See pricing page to estimate total costs\n"
     ]
    }
   ],
   "source": [
    "openai_validate_data(train_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the training and validation data to OpenAI\n",
    "\n",
    "Do not upload files repeatedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_train_file_info = client.files.create(\n",
    "    file=open(train_file_path, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "openai_valid_file_info = client.files.create(\n",
    "    file=open(test_file_path, \"rb\"), purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-VYndPZHIuBw6XHOg6LRAUPG2', bytes=21475, created_at=1729261290, filename='encoded_train_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_train_file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-OPwQ1OtKgw2qOL5byaYdcuQE', bytes=69668, created_at=1729261291, filename='encoded_test_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_valid_file_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and log to Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'gpt-3.5-turbo'\n",
    "# model = \"gpt-4o-mini-2024-07-18\"\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_ft_job_info = client.fine_tuning.jobs.create(\n",
    "    training_file=openai_train_file_info.id,\n",
    "    model=model,\n",
    "    hyperparameters={\"n_epochs\": n_epochs},\n",
    "    validation_file=openai_valid_file_info.id\n",
    ")\n",
    "\n",
    "ft_job_id = openai_ft_job_info.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Weight & Biases Sync\n",
    "\n",
    "Calling WandbLogger.sync will start polling OpenAI for the fine-tuning job results and log them when they are retrieved, see the docs for how to modify this behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Retrieving fine-tune job...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for the OpenAI fine-tuning job to finish training...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: To avoid blocking, you can call `WandbLogger.sync` with `wait_for_job_success=False` after OpenAI training completes.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Fine-tuning finished, logging metrics, model metadata, and run metadata to Weights & Biases\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging training/validation files...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>valid_loss</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>valid_mean_token_accuracy</td><td>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fine_tuned_model</td><td>ft:gpt-3.5-turbo-012...</td></tr><tr><td>status</td><td>succeeded</td></tr><tr><td>train_accuracy</td><td>1</td></tr><tr><td>train_loss</td><td>0</td></tr><tr><td>valid_loss</td><td>6.86868</td></tr><tr><td>valid_mean_token_accuracy</td><td>0.66667</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-voice-2</strong> at: <a href='https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/runs/evptcy40' target=\"_blank\">https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/runs/evptcy40</a><br/> View project at: <a href='https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test' target=\"_blank\">https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241019_005050-evptcy40/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'üéâ wandb sync completed successfully'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log to Weights and Biases\n",
    "# 79aec238fd9c8bd9024bbd0651d5518aba741797\n",
    "from wandb.integration.openai.fine_tuning import WandbLogger\n",
    "WandbLogger.sync(fine_tune_job_id=ft_job_id, project=WANDB_PROJECT, openai_client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging the fine-tuning job to W&B is straight forward. The integration will automatically log the following to W&B:\n",
    "\n",
    "- training and validation metrics (if validation data is provided)\n",
    "- log the training and validation data as W&B Tables for storage and versioning\n",
    "- log the fine-tuned model's metadata.\n",
    "\n",
    "The integration automatically creates the DAG lineage between the data and the model.\n",
    "\n",
    "> You can call the `WandbLogger` with the job id. The cell will keep running till the fine-tuning job is not complete. Once the job's status is `succeeded`, the `WandbLogger` will log metrics and data to W&B. This way you don't have to wait for the fine-tune job to be completed to call `WandbLogger.sync`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evalution and log the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to evaluate a generative model is to explore sample predictions from your evaluation set.\n",
    "\n",
    "Let's generate a few inference samples and log them to W&B and see how the performance compares to a baseline ChatGPT-3.5 model\n",
    "\n",
    "We will be evaluating using the validation dataset. In the overview tab of the run page, find the \"validation_files\" in the Artifact Inputs \n",
    "section. \n",
    "\n",
    "Clicking on it will take you to the artifacts page. Copy the artifact URI (full name) as shown in the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:q6baz7nc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-firebrand-3</strong> at: <a href='https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/runs/q6baz7nc' target=\"_blank\">https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/runs/q6baz7nc</a><br/> View project at: <a href='https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test' target=\"_blank\">https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241019_013551-q6baz7nc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:q6baz7nc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/tianyuliu/Code/llm/NLP_examples/src/llm/openai_api/Finetune API/wandb/run-20241019_014629-o913gix0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/runs/o913gix0' target=\"_blank\">atomic-wave-4</a></strong> to <a href='https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test' target=\"_blank\">https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/runs/o913gix0' target=\"_blank\">https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/runs/o913gix0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=WANDB_PROJECT,\n",
    "    job_type='eval'\n",
    ")\n",
    "\n",
    "VALIDATION_FILE_ARTIFACT_URI = 'tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/valid-file-OPwQ1OtKgw2qOL5byaYdcuQE:v0' # REPLACE THIS WITH YOUR OWN ARTIFACT URI\n",
    "\n",
    "artifact_valid = run.use_artifact(\n",
    "    VALIDATION_FILE_ARTIFACT_URI,\n",
    "    type='validation_files'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code snippet below, download the logged validation data and prepare a pandas dataframe from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded the validation data at:  /Users/tianyuliu/Code/llm/NLP_examples/src/llm/openai_api/Finetune API/artifacts/valid-file-OPwQ1OtKgw2qOL5byaYdcuQE:v0\n",
      "There are 87 validation examples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role: system</th>\n",
       "      <th>role: user</th>\n",
       "      <th>role: assistant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Identify if the clause provides that all Confi...</td>\n",
       "      <td>a. What is included, \"Confidential information...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Identify if the clause provides that all Confi...</td>\n",
       "      <td>Confidential Information provided by Disclosin...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Identify if the clause provides that all Confi...</td>\n",
       "      <td>As used in this Agreement, the terms \"CompuCom...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Identify if the clause provides that all Confi...</td>\n",
       "      <td>3.5. \"Confidential information\" means any info...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Identify if the clause provides that all Confi...</td>\n",
       "      <td>(c) Each Party agrees that, without the prior ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        role: system  \\\n",
       "0  Identify if the clause provides that all Confi...   \n",
       "1  Identify if the clause provides that all Confi...   \n",
       "2  Identify if the clause provides that all Confi...   \n",
       "3  Identify if the clause provides that all Confi...   \n",
       "4  Identify if the clause provides that all Confi...   \n",
       "\n",
       "                                          role: user role: assistant  \n",
       "0  a. What is included, \"Confidential information...              No  \n",
       "1  Confidential Information provided by Disclosin...             Yes  \n",
       "2  As used in this Agreement, the terms \"CompuCom...             Yes  \n",
       "3  3.5. \"Confidential information\" means any info...              No  \n",
       "4  (c) Each Party agrees that, without the prior ...              No  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_valid_path = artifact_valid.download()\n",
    "print(\"Downloaded the validation data at: \", artifact_valid_path)\n",
    "\n",
    "validation_file = glob.glob(f\"{artifact_valid_path}/*.table.json\")[0]\n",
    "with open(validation_file, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "validation_df = pd.DataFrame(columns=data[\"columns\"], data=data[\"data\"])\n",
    "\n",
    "print(f\"There are {len(validation_df)} validation examples\")\n",
    "run.config.update({\"num_validation_samples\":len(validation_df)})\n",
    "\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to package the data in the dataframe in the format acceptable by GPT 3.5. The format is:\n",
    "\n",
    "```\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"some system prompt\"}, {\"role\": \"user\", \"content\": \"some user prompt\"}, {\"role\": \"assistant\", \"content\": \"completion text\"}]}\n",
    "```\n",
    "\n",
    "For evaluation we don't need to pack the `{\"role\": \"assistant\", \"content\": \"completition text\"}` in `messages` as this is meant to be generated by GPT 3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role: system</th>\n",
       "      <th>role: user</th>\n",
       "      <th>role: assistant</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Identify if the clause provides that all Confi...</td>\n",
       "      <td>a. What is included, \"Confidential information...</td>\n",
       "      <td>No</td>\n",
       "      <td>[{'role': 'system', 'content': 'Identify if th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Identify if the clause provides that all Confi...</td>\n",
       "      <td>Confidential Information provided by Disclosin...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>[{'role': 'system', 'content': 'Identify if th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Identify if the clause provides that all Confi...</td>\n",
       "      <td>As used in this Agreement, the terms \"CompuCom...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>[{'role': 'system', 'content': 'Identify if th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Identify if the clause provides that all Confi...</td>\n",
       "      <td>3.5. \"Confidential information\" means any info...</td>\n",
       "      <td>No</td>\n",
       "      <td>[{'role': 'system', 'content': 'Identify if th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Identify if the clause provides that all Confi...</td>\n",
       "      <td>(c) Each Party agrees that, without the prior ...</td>\n",
       "      <td>No</td>\n",
       "      <td>[{'role': 'system', 'content': 'Identify if th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        role: system  \\\n",
       "0  Identify if the clause provides that all Confi...   \n",
       "1  Identify if the clause provides that all Confi...   \n",
       "2  Identify if the clause provides that all Confi...   \n",
       "3  Identify if the clause provides that all Confi...   \n",
       "4  Identify if the clause provides that all Confi...   \n",
       "\n",
       "                                          role: user role: assistant  \\\n",
       "0  a. What is included, \"Confidential information...              No   \n",
       "1  Confidential Information provided by Disclosin...             Yes   \n",
       "2  As used in this Agreement, the terms \"CompuCom...             Yes   \n",
       "3  3.5. \"Confidential information\" means any info...              No   \n",
       "4  (c) Each Party agrees that, without the prior ...              No   \n",
       "\n",
       "                                            messages  \n",
       "0  [{'role': 'system', 'content': 'Identify if th...  \n",
       "1  [{'role': 'system', 'content': 'Identify if th...  \n",
       "2  [{'role': 'system', 'content': 'Identify if th...  \n",
       "3  [{'role': 'system', 'content': 'Identify if th...  \n",
       "4  [{'role': 'system', 'content': 'Identify if th...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_data_format(row):\n",
    "    role_system_content = row[\"role: system\"]\n",
    "    role_system_dict = {\"role\": \"system\", \"content\": role_system_content}\n",
    "\n",
    "    role_user_content = row[\"role: user\"]\n",
    "    role_user_dict = {\"role\": \"user\", \"content\": role_user_content}\n",
    "    \n",
    "    return [role_system_dict, role_user_dict]\n",
    "\n",
    "validation_df[\"messages\"] = validation_df.apply(lambda row: eval_data_format(row), axis=1)\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation on the Fine-Tuned Model\n",
    "\n",
    "Next up we will get the fine-tuned model's id from the logged `model_metadata`. In the overview tab of the run page, find the \"model\" in the Artifact Outputs section. Clicking on it will take you to the artifacts page. Copy the artifact URI (full name) as shown in the image below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARTIFACT_URI = 'tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/model-metadata:v0' # REPLACE THIS WITH YOUR OWN ARTIFACT URI\n",
    "\n",
    "model_artifact = run.use_artifact(\n",
    "    MODEL_ARTIFACT_URI,\n",
    "    type='model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded the validation data at:  /Users/tianyuliu/Code/llm/NLP_examples/src/llm/openai_api/Finetune API/artifacts/model-metadata:v0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'ftjob-Ef468OMa5MKacvqzD0LYtGEV',\n",
       " 'created_at': 1729261503,\n",
       " 'error': \"{'code': None, 'message': None, 'param': None}\",\n",
       " 'fine_tuned_model': 'ft:gpt-3.5-turbo-0125:personal::AJiJ8bR6',\n",
       " 'finished_at': 1729261912,\n",
       " 'hyperparameters': \"{'n_epochs': 3, 'batch_size': 1, 'learning_rate_multiplier': 2}\",\n",
       " 'model': 'gpt-3.5-turbo-0125',\n",
       " 'object': 'fine_tuning.job',\n",
       " 'organization_id': 'org-v1K2Lxyjnu8PFhpx9OPExASg',\n",
       " 'result_files': \"['file-RH2WFPkKmYye7mYt99YYKR6I']\",\n",
       " 'seed': 486798962,\n",
       " 'status': 'succeeded',\n",
       " 'trained_tokens': 11415,\n",
       " 'training_file': 'file-VYndPZHIuBw6XHOg6LRAUPG2',\n",
       " 'validation_file': 'file-OPwQ1OtKgw2qOL5byaYdcuQE',\n",
       " 'estimated_finish': 'None',\n",
       " 'integrations': '[]',\n",
       " 'user_provided_suffix': 'None'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metadata_path = model_artifact.download()\n",
    "print(\"Downloaded the validation data at: \", model_metadata_path)\n",
    "\n",
    "model_metadata_file = glob.glob(f\"{model_metadata_path}/*.json\")[0]\n",
    "with open(model_metadata_file, 'r') as file:\n",
    "    model_metadata = json.load(file)\n",
    "\n",
    "model_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model = model_metadata[\"fine_tuned_model\"]\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [02:41,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "prediction_table = wandb.Table(columns=['messages', 'completion', 'target'])\n",
    "\n",
    "eval_data = []\n",
    "\n",
    "for idx, row in tqdm(validation_df.iterrows()):\n",
    "    messages = row.messages\n",
    "    target = row[\"role: assistant\"]\n",
    "\n",
    "    res = client.chat.completions.create(model=fine_tuned_model, messages=messages, max_tokens=10)\n",
    "    completion = res.choices[0].message.content\n",
    "\n",
    "    eval_data.append([messages, completion, target])\n",
    "    prediction_table.add_data(messages[1]['content'], completion, target)\n",
    "\n",
    "wandb.log({'predictions': prediction_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8620689655172413\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for e in eval_data:\n",
    "  if e[1].lower() == e[2].lower():\n",
    "    correct+=1\n",
    "\n",
    "accuracy = correct / len(eval_data)\n",
    "\n",
    "print(f\"Accuracy is {accuracy}\")\n",
    "wandb.log({\"eval/accuracy\": accuracy})\n",
    "wandb.summary[\"eval/accuracy\"] = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run evaluation on a Baseline model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [00:47,  1.82it/s]\n"
     ]
    }
   ],
   "source": [
    "baseline_prediction_table = wandb.Table(columns=['messages', 'completion', 'target'])\n",
    "\n",
    "baseline_eval_data = []\n",
    "\n",
    "for idx, row in tqdm(validation_df.iterrows()):\n",
    "    messages = row.messages\n",
    "    target = row[\"role: assistant\"]\n",
    "\n",
    "    res = client.chat.completions.create(model=\"gpt-3.5-turbo\", messages=messages, max_tokens=10)\n",
    "    completion = res.choices[0].message.content\n",
    "\n",
    "    baseline_eval_data.append([messages, completion, target])\n",
    "    baseline_prediction_table.add_data(messages[1]['content'], completion, target)\n",
    "\n",
    "wandb.log({'baseline_predictions': baseline_prediction_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accurcy is: 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "baseline_correct = 0\n",
    "for e in baseline_eval_data:\n",
    "  if e[1].lower() == e[2].lower():\n",
    "    baseline_correct+=1\n",
    "\n",
    "baseline_accuracy = baseline_correct / len(baseline_eval_data)\n",
    "print(f\"Baseline Accurcy is: {baseline_accuracy}\")\n",
    "wandb.log({\"eval/baseline_accuracy\": baseline_accuracy})\n",
    "wandb.summary[\"eval/baseline_accuracy\"] =  baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>‚ñÅ</td></tr><tr><td>eval/baseline_accuracy</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.86207</td></tr><tr><td>eval/baseline_accuracy</td><td>0.7931</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">atomic-wave-4</strong> at: <a href='https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/runs/o913gix0' target=\"_blank\">https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test/runs/o913gix0</a><br/> View project at: <a href='https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test' target=\"_blank\">https://wandb.ai/tyliu1122-university-of-technology-sydney/OpenAI-Fine-Tune-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 6 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241019_014629-o913gix0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-examples-2S-piTS9-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
