{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points When Fine Tuned the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fine Tuning Precedure\n",
    "\n",
    "- Prepare and upload training data\n",
    "- Train a new fine-tuned model\n",
    "- Evaluate results and go back to step 1 if needed\n",
    "- Use your fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use fine-tuning\n",
    "- Setting the style, tone, format, or other qualitative aspects\n",
    "- Improving reliability at producing a desired output\n",
    "- Correcting failures to follow complex prompts\n",
    "- Handling many edge cases in specific ways\n",
    "- Performing a new skill or task that’s hard to articulate in a prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating on data quality\n",
    "\n",
    "- Collect examples to target remaining issues\n",
    "    - The model is not good at specific aspect?\n",
    "- Scrutinize existing examples for issues\n",
    "    - Your model has grammar, logic or style issue\n",
    "- Consider the balance and diversity of data\n",
    "    - Model response changes significantly when making an inference\n",
    "- Make sure your training examples contain all of the informartion needed for the response\n",
    "- Look at the consistency in the training examples\n",
    "- Make sure all your traning examples are in the same format, as expected for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating on data quantity\n",
    "\n",
    "$ \\textcolor{red}{Before\\ you\\ scale\\ up\\ your\\ dataset,\\ make\\ sure\\ you\\ have\\ high\\ quality\\ dataset.}$ Or Once you’re satisfied with the quality and distribution of the examples, you can consider scaling up the number of training examples.\n",
    "\n",
    "- Fine-tuning on your current dataset\n",
    "- Fine-tuning on half of your current dataset\n",
    "- Observing the quality gap between the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating on hyperparameters\n",
    "\n",
    "Hyperparameters consist of:\n",
    "- epochs\n",
    "- learning rate multiplier\n",
    "- batch size\n",
    "\n",
    "$\\textcolor{green}{Initially\\ training\\ with\\ dafault\\ hyperparameters}$, then adjusting if you observe the following:\n",
    "\n",
    "- If the model does not follow the training data as much as expected increase the number of epochs by 1 or 2\n",
    "    - This is common for tasks which there is a single completion, such as classfication, entity extraction, structured parsing. Or those tasks which you can compute a final accuracy metric against with a reference answer.\n",
    "- If the model becomes less diverse than expected decrease the number of epochs by 1 or 2\n",
    "    - This is more common for tasks for which there are a wide range of possible good completions.\n",
    "- If the model does not appear to be converging, increase the learning rate multiplier"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
