{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assistant API with Multi-turn Conversation\n",
    "\n",
    "Once your create a Assistant, you can call the api via the Assistant.ip and Thread.ip \n",
    "Each thread id is a conversation. For a given ASSISTANT ID and THREAD ID, you can create a message, that message will automaticlly added into the chat history. That is the difference between ASSISTANT and Chat Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyuliu/Library/Caches/pypoetry/virtualenvs/nlp-examples-2S-piTS9-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Assistant\n",
    "$\\textcolor{green}{Get\\ the\\ personal\\ Assistant\\ API}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asst_neKIxzX9azeMqYlnYYT700AT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(id, asst_neKIxzX9azeMqYlnYYT700AT)</td>\n",
       "      <td>(created_at, 1729169843)</td>\n",
       "      <td>(description, None)</td>\n",
       "      <td>(instructions, You are an personal expert. Use...</td>\n",
       "      <td>(metadata, {})</td>\n",
       "      <td>(model, gpt-4o)</td>\n",
       "      <td>(name, Personal assistant)</td>\n",
       "      <td>(object, assistant)</td>\n",
       "      <td>(tools, [FileSearchTool(type='file_search', fi...</td>\n",
       "      <td>(response_format, auto)</td>\n",
       "      <td>(temperature, 1.0)</td>\n",
       "      <td>(tool_resources, ToolResources(code_interprete...</td>\n",
       "      <td>(top_p, 1.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0                         1   \\\n",
       "0  (id, asst_neKIxzX9azeMqYlnYYT700AT)  (created_at, 1729169843)   \n",
       "\n",
       "                    2                                                  3   \\\n",
       "0  (description, None)  (instructions, You are an personal expert. Use...   \n",
       "\n",
       "               4                5                           6   \\\n",
       "0  (metadata, {})  (model, gpt-4o)  (name, Personal assistant)   \n",
       "\n",
       "                    7                                                  8   \\\n",
       "0  (object, assistant)  (tools, [FileSearchTool(type='file_search', fi...   \n",
       "\n",
       "                        9                   10  \\\n",
       "0  (response_format, auto)  (temperature, 1.0)   \n",
       "\n",
       "                                                  11            12  \n",
       "0  (tool_resources, ToolResources(code_interprete...  (top_p, 1.0)  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# List all assistant\n",
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\", limit=\"20\",\n",
    ")\n",
    "personal_asistant_id = my_assistants.data[0].id\n",
    "print(my_assistants.data[0].id)\n",
    "# my_assistants.data\n",
    "pd.DataFrame(my_assistants.data)\n",
    "\n",
    "# Delete all assistant\n",
    "# response = client.beta.assistants.delete(assistants_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread (Single Round Conversation)\n",
    "Create a MESSAGE to support the single round conversation with annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tianyu Liu has a total of 9 months of industrial experience based on his roles:\n",
      "\n",
      "1. Worked as a Data Scientist at Munich Reinsurance Australia for 6 months (August 2023 - February 2024)[0].\n",
      "2. Worked as an Applied Scientist at NinjaTech AI for 3 months (March 2024 - June 2024)[0].\n",
      "[0] Resume_applied_scientist.pdf\n",
      "[1] Resume_applied_scientist.pdf\n"
     ]
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "  thread_id=thread.id,\n",
    "  role=\"user\",\n",
    "  content=\"How many industrial experience does Tianyu Liu have?\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=personal_asistant_id,\n",
    ")\n",
    "\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Message(id='msg_LUTlXQnT91FwFHrD2R97kiE7', assistant_id='asst_neKIxzX9azeMqYlnYYT700AT', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=220, file_citation=FileCitation(file_id='file-j7ZYjgIW5kjYEy3iklxjMfGT'), start_index=185, text='【12:0†Resume_applied_scientist.pdf】', type='file_citation'), FileCitationAnnotation(end_index=344, file_citation=FileCitation(file_id='file-j7ZYjgIW5kjYEy3iklxjMfGT'), start_index=309, text='【12:0†Resume_applied_scientist.pdf】', type='file_citation')], value='Tianyu Liu has a total of 9 months of industrial experience based on his roles:\\n\\n1. Worked as a Data Scientist at Munich Reinsurance Australia for 6 months (August 2023 - February 2024)【12:0†Resume_applied_scientist.pdf】.\\n2. Worked as an Applied Scientist at NinjaTech AI for 3 months (March 2024 - June 2024)【12:0†Resume_applied_scientist.pdf】.'), type='text')], created_at=1729182898, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_jL9hD7DKQAziSVTW44FtihTQ', status=None, thread_id='thread_lNAAYpHxJY5lwzqvHzBKsUfK'), Message(id='msg_lpHu1uB6qXAZLDwhgJtL1xPM', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='How many industrial experience does Tianyu Liu have?'), type='text')], created_at=1729182896, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_lNAAYpHxJY5lwzqvHzBKsUfK'), Message(id='msg_zw9hEBNOGpPMuymlk2QnKjZb', assistant_id='asst_neKIxzX9azeMqYlnYYT700AT', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Your last question was: \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"'), type='text')], created_at=1729182779, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_SQdQpybFiVJ4xGrP8vL3Ct3f', status=None, thread_id='thread_lNAAYpHxJY5lwzqvHzBKsUfK'), Message(id='msg_ioh7ApEl5h75CNZUkGH6v4s3', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What is my last question?'), type='text')], created_at=1729182776, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_lNAAYpHxJY5lwzqvHzBKsUfK'), Message(id='msg_CFVXUq7FINBryyMmMpzeULFu', assistant_id='asst_neKIxzX9azeMqYlnYYT700AT', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Certainly! To solve the equation \\\\(3x + 11 = 14\\\\), you can follow these steps:\\n\\n1. Subtract 11 from both sides of the equation to get the term with \\\\(x\\\\) by itself:\\n   \\\\[\\n   3x + 11 - 11 = 14 - 11\\n   \\\\]\\n   \\\\[\\n   3x = 3\\n   \\\\]\\n\\n2. Divide both sides by 3 to solve for \\\\(x\\\\):\\n   \\\\[\\n   \\\\frac{3x}{3} = \\\\frac{3}{3}\\n   \\\\]\\n   \\\\[\\n   x = 1\\n   \\\\]\\n\\nTherefore, the solution to the equation is \\\\(x = 1\\\\).'), type='text')], created_at=1729182753, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_hHuBpuKwx3QyOdnUE8RbuEcH', status=None, thread_id='thread_lNAAYpHxJY5lwzqvHzBKsUfK'), Message(id='msg_tLe7Ztq3PUj5Mq0d91R5SXqS', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1729182751, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_lNAAYpHxJY5lwzqvHzBKsUfK'), Message(id='msg_STT75iGJxPCeHnrdClLMNQr9', assistant_id='asst_neKIxzX9azeMqYlnYYT700AT', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Your last question was: \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"'), type='text')], created_at=1729180296, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_cgM2kEgaDTqXqyW6h25yeh8G', status=None, thread_id='thread_lNAAYpHxJY5lwzqvHzBKsUfK'), Message(id='msg_Ltg4j2kF1VxKxWA2hV4Fayf1', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What is my last question?'), type='text')], created_at=1729180294, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_lNAAYpHxJY5lwzqvHzBKsUfK'), Message(id='msg_ykHv1r3RxNyC9qPu52biqpz9', assistant_id='asst_neKIxzX9azeMqYlnYYT700AT', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='To solve the equation \\\\(3x + 11 = 14\\\\), follow these steps:\\n\\n1. Subtract 11 from both sides of the equation to isolate the term with \\\\(x\\\\):\\n   \\\\[\\n   3x + 11 - 11 = 14 - 11\\n   \\\\]\\n   \\\\[\\n   3x = 3\\n   \\\\]\\n\\n2. Divide both sides by 3 to solve for \\\\(x\\\\):\\n   \\\\[\\n   \\\\frac{3x}{3} = \\\\frac{3}{3}\\n   \\\\]\\n   \\\\[\\n   x = 1\\n   \\\\]\\n\\nSo, the solution to the equation is \\\\(x = 1\\\\).'), type='text')], created_at=1729180272, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_XTdGfpuKO8DZBNgMPEbCAuX2', status=None, thread_id='thread_lNAAYpHxJY5lwzqvHzBKsUfK'), Message(id='msg_oD4b3PtAHLsfOkRe2B6PIRV4', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='I need to solve the equation `3x + 11 = 14`. Can you help me?'), type='text')], created_at=1729180270, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_lNAAYpHxJY5lwzqvHzBKsUfK')]\n"
     ]
    }
   ],
   "source": [
    "# Check all the message in the Thread vai Thread ID\n",
    "thread_messages = client.beta.threads.messages.list(thread.id)\n",
    "print(thread_messages.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Assistant with Multi-turn conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread created with ID: thread_mBjd9rYGlKUQzajwrR0HzMrO\n",
      "Assistant: Tianyu Liu has a total of 8 months of industrial experience. This includes 3 months as an Applied Scientist at NinjaTech AI and 6 months as a Data Scientist at Munich Reinsurance Australia【4:0†Resume_applied_scientist.pdf】.\n",
      "Message sent: What is my last question\n",
      "Assistant: Your last question was: \"How many industrial experience does Tianyu Liu have?\"\n",
      "Ending conversation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to create a new thread\n",
    "def create_thread(message_content):\n",
    "    \"\"\"\n",
    "    Creates a new thread and sends the first message.\n",
    "    \"\"\"\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message_content\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Thread created with ID: {thread.id}\")\n",
    "    return thread.id\n",
    "\n",
    "# Function to run the assistant within the thread\n",
    "def run_assistant(assistant_id, thread_id):\n",
    "    \"\"\"\n",
    "    Executes the assistant run in the created thread and returns the response.\n",
    "    \"\"\"\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id\n",
    "    )\n",
    "    \n",
    "    messages = list(client.beta.threads.messages.list(thread_id=thread_id, run_id=run.id))\n",
    "    \n",
    "    message_content = messages[0].content[0].text.value\n",
    "    return message_content\n",
    "\n",
    "# Function to send a message in the thread\n",
    "def send_message(thread_id, message_content):\n",
    "    \"\"\"\n",
    "    Sends a message to the assistant in the ongoing thread.\n",
    "    \"\"\"\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        content=message_content,\n",
    "        role=\"user\"\n",
    "    )\n",
    "    print(f\"Message sent: {message_content}\")\n",
    "\n",
    "# Main loop for conversation\n",
    "def multi_turn_conversation(assistant_id):\n",
    "    \"\"\"\n",
    "    Handles multi-turn conversation with the assistant.\n",
    "    \"\"\"\n",
    "    # Ask user for the initial message and create a thread\n",
    "    user_input = input(\"You: \")\n",
    "    thread_id = create_thread(user_input)\n",
    "\n",
    "    while True:\n",
    "        # Get the assistant's response\n",
    "        assistant_response = run_assistant(assistant_id, thread_id)\n",
    "        print(f\"Assistant: {assistant_response}\")\n",
    "        \n",
    "        # Get next user input\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"Ending conversation.\")\n",
    "            break\n",
    "        \n",
    "        # Send the new user message and continue the conversation\n",
    "        send_message(thread_id, user_input)\n",
    "\n",
    "# Set your assistant ID (replace with actual assistant ID)\n",
    "assistant_id = personal_asistant_id\n",
    "\n",
    "# Start the multi-turn conversation\n",
    "multi_turn_conversation(assistant_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Assistant with Multi-turn conversation via Gradio WebUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyuliu/Library/Caches/pypoetry/virtualenvs/nlp-examples-2S-piTS9-py3.12/lib/python3.12/site-packages/gradio/components/chatbot.py:222: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Function to create a new thread\n",
    "def create_thread(message_content):\n",
    "    \"\"\"\n",
    "    Creates a new thread and sends the first message.\n",
    "    \"\"\"\n",
    "    thread = client.beta.threads.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message_content\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return thread.id\n",
    "\n",
    "# Function to run the assistant within the thread\n",
    "def run_assistant(assistant_id, thread_id):\n",
    "    \"\"\"\n",
    "    Executes the assistant run in the created thread and returns the response.\n",
    "    \"\"\"\n",
    "    run = client.beta.threads.runs.create_and_poll(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id\n",
    "    )\n",
    "    \n",
    "    messages = list(client.beta.threads.messages.list(thread_id=thread_id, run_id=run.id))\n",
    "    \n",
    "    message_content = messages[0].content[0].text.value\n",
    "    return message_content\n",
    "\n",
    "# Function to send a message in the thread\n",
    "def send_message(thread_id, message_content):\n",
    "    \"\"\"\n",
    "    Sends a message to the assistant in the ongoing thread.\n",
    "    \"\"\"\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        content=message_content,\n",
    "        role=\"user\"\n",
    "    )\n",
    "\n",
    "# Function to handle conversation logic for Gradio, including chat history\n",
    "def chat(assistant_id, thread_id, user_message, chat_history):\n",
    "    \"\"\"\n",
    "    Sends a user message and returns the assistant's response and updated chat history.\n",
    "    \"\"\"\n",
    "    if not thread_id:  # Check if thread_id is None or empty\n",
    "        # Create a new thread if it's the first message\n",
    "        thread_id = create_thread(user_message)\n",
    "    else:\n",
    "        # Send message in an existing thread\n",
    "        send_message(thread_id, user_message)\n",
    "    \n",
    "    # Get assistant's response\n",
    "    assistant_response = run_assistant(assistant_id, thread_id)\n",
    "    \n",
    "    # Update the chat history\n",
    "    chat_history.append((\"You\", user_message))\n",
    "    chat_history.append((\"Assistant\", assistant_response))\n",
    "    \n",
    "    return chat_history, thread_id\n",
    "\n",
    "# Initial variables\n",
    "assistant_id = personal_asistant_id\n",
    "thread_id = None\n",
    "chat_history = []\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# AI Personal Assistant\")\n",
    "\n",
    "    assistant_id_input = gr.Textbox(value=assistant_id, label=\"Assistant ID\", visible=False)  # Set the assistant ID\n",
    "    thread_id_input = gr.Textbox(value=None, label=\"Thread ID (for multi-turn)\", visible=False)  # Hidden Thread ID\n",
    "    \n",
    "    chatbot = gr.Chatbot(label=\"Chat History\")  # Chatbot component to show the conversation\n",
    "    user_input = gr.Textbox(label=\"You\", placeholder=\"Type your message here...\")\n",
    "\n",
    "    def process_chat(user_message, assistant_id_input, thread_id_input, chat_history):\n",
    "        # If thread_id_input is empty or None, set it to None (to avoid passing empty strings)\n",
    "        thread_id_input = thread_id_input if thread_id_input else None\n",
    "        chat_history, new_thread_id = chat(assistant_id_input, thread_id_input, user_message, chat_history)\n",
    "        return chat_history, new_thread_id\n",
    "    \n",
    "    user_input.submit(\n",
    "        process_chat, \n",
    "        inputs=[user_input, assistant_id_input, thread_id_input, chatbot], \n",
    "        outputs=[chatbot, thread_id_input]\n",
    "    )\n",
    "\n",
    "# Launch Gradio interface\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-examples-2S-piTS9-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
