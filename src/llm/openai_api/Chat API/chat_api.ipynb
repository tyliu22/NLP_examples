{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a helpful assistant here to provide you with information and assistance. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# chat\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who are you!\"}\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.2\n",
    ")\n",
    "# print(chat_completion)\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image shows a beautifully calm and inviting natural landscape. There's a wooden boardwalk path that extends through tall, lush green grass, giving the impression of a peaceful walkway through a marsh or wetland area. Dominating the scene are the vibrant blues and whites of a sweeping sky filled with fluffy clouds. The horizon is fringed with clusters of trees and shrubs, enhancing the feeling of wide, open spaces. The scene is rich with natural colors and suggests a serene, quiet environment, perfect for a walk to connect with nature.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "        ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_IVhROO0eir8hraopmvpEu0hL', function=Function(arguments='{\"location\":\"Boston, MA\",\"unit\":\"fahrenheit\"}', name='get_current_weather'), type='function')]))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"),)\n",
    "\n",
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "          },\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "      },\n",
    "    }\n",
    "  }\n",
    "]\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "\n",
    "print(completion.choices[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', function_call=None, tool_calls=None)\n",
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.00074339914, top_logprobs=[TopLogprob(token='Hello', bytes=[72, 101, 108, 108, 111], logprob=-0.00074339914), TopLogprob(token='Hi', bytes=[72, 105], logprob=-7.215717)]), ChatCompletionTokenLogprob(token='!', bytes=[33], logprob=-6.511407e-06, top_logprobs=[TopLogprob(token='!', bytes=[33], logprob=-6.511407e-06), TopLogprob(token=' there', bytes=[32, 116, 104, 101, 114, 101], logprob=-11.962539)]), ChatCompletionTokenLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-0.000100205485, top_logprobs=[TopLogprob(token=' How', bytes=[32, 72, 111, 119], logprob=-0.000100205485), TopLogprob(token=' What', bytes=[32, 87, 104, 97, 116], logprob=-9.210141)]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-4.3202e-07, top_logprobs=[TopLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-4.3202e-07), TopLogprob(token=' may', bytes=[32, 109, 97, 121], logprob=-14.855013)]), ChatCompletionTokenLogprob(token=' I', bytes=[32, 73], logprob=0.0, top_logprobs=[TopLogprob(token=' I', bytes=[32, 73], logprob=0.0), TopLogprob(token=' help', bytes=[32, 104, 101, 108, 112], logprob=-17.810692)]), ChatCompletionTokenLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.4674583, top_logprobs=[TopLogprob(token=' assist', bytes=[32, 97, 115, 115, 105, 115, 116], logprob=-0.4674583), TopLogprob(token=' help', bytes=[32, 104, 101, 108, 112], logprob=-0.985086)]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0, top_logprobs=[TopLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=0.0), TopLogprob(token=' ', bytes=[32], logprob=-22.675377)]), ChatCompletionTokenLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0, top_logprobs=[TopLogprob(token=' today', bytes=[32, 116, 111, 100, 97, 121], logprob=0.0), TopLogprob(token='?', bytes=[63], logprob=-18.317024)]), ChatCompletionTokenLogprob(token='?', bytes=[63], logprob=-0.0013584481, top_logprobs=[TopLogprob(token='?', bytes=[63], logprob=-0.0013584481), TopLogprob(token='?\\n', bytes=[63, 10], logprob=-6.603226)])], refusal=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"),)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ],\n",
    "    logprobs=True,\n",
    "    top_logprobs=2\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)\n",
    "print(completion.choices[0].logprobs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-examples-2S-piTS9-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
