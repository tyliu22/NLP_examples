{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pleae copy folder https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/custom-voice/python/customvoice and keep the same folder structure as github.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azure'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPleae copy folder https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/custom-voice/python/customvoice and keep the same folder structure as github.\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[1;32m     10\u001b[0m     quit()\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mazure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcognitiveservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspeech\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspeechsdk\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'azure'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from time import sleep\n",
    "import os\n",
    "import logging\n",
    "try:\n",
    "    import customvoice\n",
    "except ImportError:\n",
    "    print('Pleae copy folder https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/samples/custom-voice/python/customvoice and keep the same folder structure as github.' )\n",
    "    quit()\n",
    "import azure.cognitiveservices.speech as speechsdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_personal_voice(project_id: str,\n",
    "                          consent_id: str, consent_file_path: str, voice_talent_name: str, company_name: str,\n",
    "                          personal_voice_id: str, audio_folder: str):\n",
    "    # create project\n",
    "    project = customvoice.Project.create(config, project_id, customvoice.ProjectKind.PersonalVoice)\n",
    "    print('Project created. project id: %s' % project.id)\n",
    "\n",
    "    # upload consent\n",
    "    consent = customvoice.Consent.create(config, project_id, consent_id, voice_talent_name, company_name, consent_file_path, 'en-us')\n",
    "    if consent.status == customvoice.Status.Failed:\n",
    "        print('Create consent failed. consent id: %s' % consent.id)\n",
    "        raise Exception\n",
    "    elif consent.status == customvoice.Status.Succeeded:\n",
    "        print('Create consent succeeded. consent id: %s' % consent.id)\n",
    "\n",
    "    # create personal voice\n",
    "    personal_voice = customvoice.PersonalVoice.create(config, project_id, personal_voice_id, consent_id, audio_folder)\n",
    "    if personal_voice.status == customvoice.Status.Failed:\n",
    "        print('Create personal voice failed. personal voice id: %s' % personal_voice.id)\n",
    "        raise Exception\n",
    "    elif personal_voice.status == customvoice.Status.Succeeded:\n",
    "        print('Create personal voice succeeded. personal voice id: %s, speaker profile id: %s' % (personal_voice.id, personal_voice.speaker_profile_id))\n",
    "    return personal_voice.speaker_profile_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_synthesis_to_wave_file(text: str, output_file_path: str, speaker_profile_id: str):\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=config.key, region=config.region)\n",
    "    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Riff24Khz16BitMonoPcm)\n",
    "    file_config = speechsdk.audio.AudioOutputConfig(filename=output_file_path)\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=file_config)\n",
    "\n",
    "\n",
    "    # use PhoenixLatestNeural if you want word boundary event.  We will support events on DragonLatestNeural in the future.\n",
    "    ssml = \"<speak version='1.0' xml:lang='en-US' xmlns='http://www.w3.org/2001/10/synthesis' \" \\\n",
    "           \"xmlns:mstts='http://www.w3.org/2001/mstts'>\" \\\n",
    "           \"<voice name='DragonLatestNeural'>\" \\\n",
    "           \"<mstts:ttsembedding speakerProfileId='%s'/>\" \\\n",
    "           \"<mstts:express-as style='Prompt'>\" \\\n",
    "           \"<lang xml:lang='en-US'> %s </lang>\" \\\n",
    "           \"</mstts:express-as>\" \\\n",
    "           \"</voice></speak> \" % (speaker_profile_id, text)\n",
    "\n",
    "    def word_boundary(evt):\n",
    "        print(f\"Word Boundary: Text='{evt.text}', Audio offset={evt.audio_offset / 10000}ms, Duration={evt.duration / 10000}ms, text={evt.text}\")\n",
    "\n",
    "    speech_synthesizer.synthesis_word_boundary.connect(word_boundary)\n",
    "    result = speech_synthesizer.speak_ssml_async(ssml).get()\n",
    "\n",
    "    # Check result\n",
    "    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(\"Speech synthesized for text [{}], and the audio was saved to [{}]\".format(text, output_file_path))\n",
    "        print(\"result id: {}\".format(result.result_id))\n",
    "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"result id: {}\".format(result.result_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up(project_id: str, consent_id: str, personal_voice_id: str):\n",
    "    customvoice.PersonalVoice.delete(config, personal_voice_id)\n",
    "    customvoice.Consent.delete(config, consent_id)\n",
    "    customvoice.Project.delete(config, project_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'eastus' # eastus, westeurope, southeastasia\n",
    "key = 'your speech key here'\n",
    "\n",
    "\n",
    "logging.basicConfig(filename=\"customvoice.log\",\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    filemode='w')\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "config = customvoice.Config(key, region, logger)\n",
    "\n",
    "\n",
    "project_id = 'personal-voice-project-1'\n",
    "consent_id = 'personal-voice-consent-1'\n",
    "personal_voice_id  = 'personal-voice-1'\n",
    "\n",
    "try:\n",
    "    # step 1: create personal voice\n",
    "    # Need consent file and audio file to create personal vocie.\n",
    "    # This is consent file template.\n",
    "    # I [voice talent name] am aware that recordings of my voice will be used by [company name] to create and use a synthetic version of my voice.\n",
    "    # You can find sample consent file here\n",
    "    # https://github.com/Azure-Samples/Cognitive-Speech-TTS/blob/master/CustomVoice/Sample%20Data/Individual%20utterances%20%2B%20matching%20script/VoiceTalentVerbalStatement.wav\n",
    "    consent_file_path = r'TestData\\\\VoiceTalentVerbalStatement.wav'\n",
    "    voice_talent_name = 'Sample Voice Actor'\n",
    "    company_name = 'Contoso'\n",
    "\n",
    "    # Need 5 - 90 seconds audio file.\n",
    "    # You can find sample audio file here.\n",
    "    # https://github.com/Azure-Samples/Cognitive-Speech-TTS/blob/master/CustomVoice/Sample%20Data/Individual%20utterances%20%2B%20matching%20script/SampleAudios.zip\n",
    "    audio_folder = r'TestData\\\\voice\\\\'\n",
    "    speaker_profile_id = create_personal_voice(project_id, \n",
    "                                            consent_id, consent_file_path, voice_talent_name, company_name,\n",
    "                                            personal_voice_id, audio_folder)\n",
    "\n",
    "    # step 2: synthesis wave\n",
    "    text = 'This is zero shot voice. Test 2.'\n",
    "    output_wave_file_path = 'output_sdk.wav'\n",
    "    speech_synthesis_to_wave_file(text, output_wave_file_path, speaker_profile_id)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    # Optional step 3: clean up, if you don't need this voice to synthesis more content.\n",
    "    clean_up(project_id, consent_id, personal_voice_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-examples-2S-piTS9-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
